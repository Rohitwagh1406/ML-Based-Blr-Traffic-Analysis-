{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f81f240",
   "metadata": {},
   "source": [
    "# Traffic Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ec12d7-27cc-47b7-b80c-f8dba04f0874",
   "metadata": {},
   "source": [
    "# Traffic Analysis Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88c8798",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89f5343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'Banglore_traffic_Dataset 2.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'Date' column to datetime format and extract time-based features\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Year'] = df['Date'].dt.year\n",
    "df['Month'] = df['Date'].dt.month\n",
    "df['Day'] = df['Date'].dt.day\n",
    "df['Weekday'] = df['Date'].dt.weekday\n",
    "\n",
    "# Encode categorical columns ('Weather Conditions' and 'Roadwork and Construction Activity')\n",
    "label_encoder = LabelEncoder()\n",
    "df['Weather Conditions'] = label_encoder.fit_transform(df['Weather Conditions'])\n",
    "df['Roadwork and Construction Activity'] = label_encoder.fit_transform(df['Roadwork and Construction Activity'])\n",
    "\n",
    "# Drop the original 'Date' column\n",
    "df.drop(columns=['Date'], inplace=True)\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb4f6b5",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Exploratory Data Analysis (EDA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4f63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualizing the distribution of Traffic Volume\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['Traffic Volume'], kde=True, bins=30)\n",
    "plt.title('Distribution of Traffic Volume')\n",
    "plt.xlabel('Traffic Volume')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap to identify relationships\n",
    "correlation_matrix = df.corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Correlation Heatmap of Features')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for Traffic Volume vs Average Speed\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Average Speed', y='Traffic Volume', data=df)\n",
    "plt.title('Traffic Volume vs Average Speed')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.show()\n",
    "\n",
    "# Scatter plot for Traffic Volume vs Congestion Level\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Congestion Level', y='Traffic Volume', data=df)\n",
    "plt.title('Traffic Volume vs Congestion Level')\n",
    "plt.xlabel('Congestion Level')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2105096",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Model Building\n",
    "### Traffic Volume Prediction - Random Forest Regressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8a2911",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X = df.drop(columns=['Traffic Volume', 'Congestion Level', 'Incident Reports'])\n",
    "y_traffic_volume = df['Traffic Volume']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_traffic_volume, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "(mse, rmse, r2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a998e7c",
   "metadata": {},
   "source": [
    "\n",
    "### Congestion Level Classification - Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556975e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Categorize congestion levels into Low, Medium, High\n",
    "congestion_labels = ['Low', 'Medium', 'High']\n",
    "df['Congestion Level Category'] = pd.cut(df['Congestion Level'], bins=[0, 33, 66, 100], labels=congestion_labels)\n",
    "\n",
    "# Separate features and target variable for classification\n",
    "y_congestion = df['Congestion Level Category']\n",
    "X_classification = df.drop(columns=['Congestion Level', 'Traffic Volume', 'Incident Reports', 'Congestion Level Category'])\n",
    "\n",
    "# Split the data for classification\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_classification, y_congestion, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train_class, y_train_class)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_class = rf_classifier.predict(X_test_class)\n",
    "\n",
    "# Evaluate the model\n",
    "classification_rep = classification_report(y_test_class, y_pred_class, target_names=congestion_labels)\n",
    "\n",
    "classification_rep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e09925",
   "metadata": {},
   "source": [
    "\n",
    "### Incident Detection - Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa647eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare the data for incident detection\n",
    "y_incident = df['Incident Reports']\n",
    "X_incident_classification = df.drop(columns=['Congestion Level', 'Traffic Volume', 'Incident Reports'])\n",
    "\n",
    "# Split the data for incident detection\n",
    "X_train_incident, X_test_incident, y_train_incident, y_test_incident = train_test_split(X_incident_classification, y_incident, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize numerical features for incident detection\n",
    "scaler = StandardScaler()\n",
    "X_train_incident_scaled = scaler.fit_transform(X_train_incident)\n",
    "X_test_incident_scaled = scaler.transform(X_test_incident)\n",
    "\n",
    "# Initialize Random Forest Classifier for incident detection\n",
    "rf_incident_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_incident_classifier.fit(X_train_incident_scaled, y_train_incident)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred_incident = rf_incident_classifier.predict(X_test_incident_scaled)\n",
    "\n",
    "# Evaluate the model performance\n",
    "incident_classification_report = classification_report(y_test_incident, y_pred_incident)\n",
    "\n",
    "incident_classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b5ac2a",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Traffic Flow Optimization - KMeans Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf37c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Select only the numeric columns for clustering\n",
    "X_clustering = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Normalize the features for clustering\n",
    "scaler_for_clustering = StandardScaler()\n",
    "X_clustering_scaled = scaler_for_clustering.fit_transform(X_clustering)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df['Cluster'] = kmeans.fit_predict(X_clustering_scaled)\n",
    "\n",
    "# Visualize the clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(x='Average Speed', y='Traffic Volume', hue='Cluster', palette='Set1', data=df, s=100, alpha=0.7)\n",
    "plt.title('Traffic Clusters Based on Traffic Volume and Average Speed')\n",
    "plt.xlabel('Average Speed (km/h)')\n",
    "plt.ylabel('Traffic Volume')\n",
    "plt.legend(title='Cluster')\n",
    "plt.show()\n",
    "\n",
    "# Analyze cluster centers\n",
    "cluster_centers = kmeans.cluster_centers_\n",
    "cluster_centers_df = pd.DataFrame(cluster_centers, columns=X_clustering.columns)\n",
    "cluster_centers_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e91cf",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Model Evaluation and Fine-tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b9f4e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 15\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Fine-tuning Random Forest Regressor for Traffic Volume Prediction\u001b[39;00m\n\u001b[1;32m     10\u001b[0m param_grid_rf_regressor \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn_estimators\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m200\u001b[39m],\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_depth\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m20\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m],\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin_samples_split\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m5\u001b[39m]\n\u001b[1;32m     14\u001b[0m }\n\u001b[0;32m---> 15\u001b[0m grid_search_rf_regressor \u001b[38;5;241m=\u001b[39m GridSearchCV(\u001b[43mRandomForestRegressor\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m), param_grid_rf_regressor, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m grid_search_rf_regressor\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     18\u001b[0m best_rf_regressor \u001b[38;5;241m=\u001b[39m grid_search_rf_regressor\u001b[38;5;241m.\u001b[39mbest_estimator_\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomForestRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "## 5. Model Evaluation and Fine-tuning\n",
    "# In this section, we will evaluate the models using various metrics like **Accuracy**, **F1-Score**, **RMSE**, and **MAE**. Additionally, we will fine-tune the models using techniques like **GridSearchCV** to improve performance.\n",
    "\n",
    "\n",
    "# Add code to fine-tune models using GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Fine-tuning Random Forest Regressor for Traffic Volume Prediction\n",
    "param_grid_rf_regressor = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "grid_search_rf_regressor = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_rf_regressor, cv=3, scoring='neg_mean_squared_error')\n",
    "grid_search_rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "best_rf_regressor = grid_search_rf_regressor.best_estimator_\n",
    "y_pred_best_rf_regressor = best_rf_regressor.predict(X_test)\n",
    "rmse_best_rf_regressor = mean_squared_error(y_test, y_pred_best_rf_regressor, squared=False)\n",
    "\n",
    "# Fine-tuning Random Forest Classifier for Congestion Level Classification\n",
    "param_grid_rf_classifier = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "grid_search_rf_classifier = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf_classifier, cv=3, scoring='accuracy')\n",
    "grid_search_rf_classifier.fit(X_train_class, y_train_class)\n",
    "\n",
    "best_rf_classifier = grid_search_rf_classifier.best_estimator_\n",
    "y_pred_best_rf_classifier = best_rf_classifier.predict(X_test_class)\n",
    "classification_rep_best_rf_classifier = classification_report(y_test_class, y_pred_best_rf_classifier, target_names=congestion_labels)\n",
    "\n",
    "rmse_best_rf_regressor, classification_rep_best_rf_classifier\n",
    "\n",
    "\n",
    "# Add the evaluation cells to the notebook\n",
    "nb.cells.append(model_evaluation_cell)\n",
    "nb.cells.append(model_evaluation_code)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e8f2a-b91c-467d-9bae-75dc9e02a87f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/Satarupa_fixed.ipynb'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Move file to a common directory for download\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/mnt/data/Satarupa_fixed.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./Satarupa_fixed.ipynb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile is ready to download. Check your working directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/shutil.py:435\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    434\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 435\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/Satarupa_fixed.ipynb'"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "# Move file to a common directory for download\n",
    "shutil.copy(\"/mnt/data/Satarupa_fixed.ipynb\", \"./Satarupa_fixed.ipynb\")\n",
    "\n",
    "print(\"File is ready to download. Check your working directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee8300-d406-4669-8734-8109fffb2237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
